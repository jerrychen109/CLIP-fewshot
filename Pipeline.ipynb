{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python388jvsc74a57bd02a41893882cd6a4f9de9c4407ee80149143837d532b553c8457b9b80809c1765",
      "display_name": "Python 3.8.8 64-bit ('cs197_env': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "metadata": {
      "interpreter": {
        "hash": "2a41893882cd6a4f9de9c4407ee80149143837d532b553c8457b9b80809c1765"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerrychen109/cs197/blob/master/Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs5lnQcwW8q7",
        "outputId": "cb8634be-5fc6-4288-a745-c992db1cef8f"
      },
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# # Enter the foldername in your Drive where you have saved the unzipped\n",
        "# # assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
        "# FOLDERNAME = \"/CS197\"\n",
        "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# import sys\n",
        "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "####### TODO: Download the CIFAR-10 dataset\n",
        "import torch\n",
        "from utils.data_utils import *\n",
        "from utils.image_utils import *\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# print(torch.tensor([1, 2, 3]))\n",
        "CIFAR10_DIR = 'datasets/cifar-10-batches-py'\n",
        "TRAIN_BATCHES = [os.path.join(CIFAR10_DIR, batch_path) for batch_path in [\n",
        "    'data_batch_1',\n",
        "    'data_batch_2',\n",
        "    'data_batch_3',\n",
        "    'data_batch_4',\n",
        "    'data_batch_5'\n",
        "]]\n",
        "TEST_BATCH = os.path.join(CIFAR10_DIR, 'test_batch')\n",
        "\n",
        "train_data, train_labels = load_cifar10(TRAIN_BATCHES)\n",
        "test_data, test_labels = load_cifar10_batch(TEST_BATCH)\n",
        "print (train_data.shape, train_labels.shape)\n",
        "print (test_data.shape, test_labels.shape)\n",
        "print(\"Resizing to 224x224\")\n",
        "train_data = resize_images(train_data)\n",
        "print(train_data.shape)\n",
        "test_data = resize_images(test_data)\n",
        "print(test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50000, 3, 32, 32]) torch.Size([50000])\n",
            "torch.Size([10000, 3, 32, 32]) torch.Size([10000])\n",
            "Resizing to 224x224\n",
            "torch.Size([50000, 3, 224, 224])\n",
            "torch.Size([10000, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyiG1l9YWXGS",
        "outputId": "1ba8cae9-e05b-4b08-edfd-af4cbc7cc4e3"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA version: 11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ12TwNsd2gu",
        "outputId": "82d4adc2-8909-40d0-c86c-f01dac1fe386"
      },
      "source": [
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
            "\u001b[K     |███████████████████████         | 834.1MB 1.3MB/s eta 0:04:07tcmalloc: large alloc 1147494400 bytes == 0x55fcef5d0000 @  0x7f179c8b2615 0x55fcb5ff806c 0x55fcb60d7eba 0x55fcb5ffae8d 0x55fcb60ec99d 0x55fcb606efe9 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606ee50 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606b86a 0x55fcb60ed7c6 0x55fcb606aee2 0x55fcb60ed7c6 0x55fcb606aee2 0x55fcb60ed7c6 0x55fcb606aee2 0x55fcb60ed7c6 0x55fcb616f431 0x55fcb60d0049 0x55fcb603ac84 0x55fcb5ffb8e9 0x55fcb606fade 0x55fcb5ffc69a 0x55fcb606aa45 0x55fcb6069e0d 0x55fcb5ffc77a 0x55fcb606aa45 0x55fcb5ffc69a 0x55fcb606aa45\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7MB 1.2MB/s eta 0:01:27tcmalloc: large alloc 1434370048 bytes == 0x55fd33c26000 @  0x7f179c8b2615 0x55fcb5ff806c 0x55fcb60d7eba 0x55fcb5ffae8d 0x55fcb60ec99d 0x55fcb606efe9 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606ee50 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606b86a 0x55fcb60ed7c6 0x55fcb606aee2 0x55fcb60ed7c6 0x55fcb606aee2 0x55fcb60ed7c6 0x55fcb606aee2 0x55fcb60ed7c6 0x55fcb616f431 0x55fcb60d0049 0x55fcb603ac84 0x55fcb5ffb8e9 0x55fcb606fade 0x55fcb5ffc69a 0x55fcb606aa45 0x55fcb6069e0d 0x55fcb5ffc77a 0x55fcb606aa45 0x55fcb5ffc69a 0x55fcb606aa45\n",
            "\u001b[K     |████████████████████████████████| 1156.7MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55fd89412000 @  0x7f179c8b2615 0x55fcb5ff806c 0x55fcb60d7eba 0x55fcb5ffae8d 0x55fcb60ec99d 0x55fcb606efe9 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606ac9e 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606ac9e 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606ac9e 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606ac9e 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606ac9e 0x55fcb5ffc69a 0x55fcb606ac9e 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606b86a 0x55fcb6069b0e 0x55fcb5ffc77a 0x55fcb606b86a 0x55fcb6069b0e 0x55fcb5ffce11\n",
            "\u001b[K     |████████████████████████████████| 1156.8MB 16kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 220kB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/b5/5da463f9c7823e0e575e9908d004e2af4b36efa8d02d3d6dad57094fcb11/ftfy-6.0.1.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.1-cp37-none-any.whl size=41573 sha256=1037d34adfeb9835b1e7f861524bea35183aaaf2c05cfdd95f331e4d8be83c87\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/73/c7/9056e14b04919e5c262fe80b54133b1a88d73683d05d7ac65c\n",
            "Successfully built ftfy\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, ftfy\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed ftfy-6.0.1 torch-1.7.1+cu110 torchvision-0.8.2+cu110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arWz0UQSd4XC",
        "outputId": "3b9ca347-2d14-49e0-a9f9-b0dc3fa2b3e9"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version: 1.7.1+cu110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phsQiFu8d6xD"
      },
      "source": [
        "MODELS = {\n",
        "    \"RN50\": \"https://openaipublic.azureedge.net/clip/models/afeb0e10f9e5a86da6080e35cf09123aca3b358a0c3e3b6c78a7b63bc04b6762/RN50.pt\",\n",
        "    \"RN101\": \"https://openaipublic.azureedge.net/clip/models/8fa8567bab74a42d41c5915025a8e4538c3bdbe8804a470a72f30b0d94fab599/RN101.pt\",\n",
        "    \"RN50x4\": \"https://openaipublic.azureedge.net/clip/models/7e526bd135e493cef0776de27d5f42653e6b4c8bf9e0f653bb11773263205fdd/RN50x4.pt\",\n",
        "    \"ViT-B/32\": \"https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\",    \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K53T_iHZd7-W",
        "outputId": "946c3d07-784f-463d-b5aa-212ecbf40e89"
      },
      "source": [
        "! wget {MODELS[\"ViT-B/32\"]} -O model.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-26 19:10:24--  https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.40, 13.107.213.40, 2620:1ec:bdf::40, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 353976522 (338M) [application/octet-stream]\n",
            "Saving to: ‘model.pt’\n",
            "\n",
            "model.pt            100%[===================>] 337.58M   255MB/s    in 1.3s    \n",
            "\n",
            "2021-04-26 19:10:25 (255 MB/s) - ‘model.pt’ saved [353976522/353976522]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl4SW9Djd9Vt",
        "outputId": "ecbee902-1cc8-4a57-e177-b71864d6fb8b"
      },
      "source": [
        "model = torch.jit.load(\"model.pt\").cuda().eval()\n",
        "input_resolution = model.input_resolution.item()\n",
        "context_length = model.context_length.item()\n",
        "vocab_size = model.vocab_size.item()\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Input resolution:\", input_resolution)\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model parameters: 151,277,313\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh3rtIhrd-el"
      },
      "source": [
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "from PIL import Image\n",
        "from torchvision.datasets import CIFAR10, CIFAR100\n",
        "from utils import *\n",
        "from prototype import Prototype\n",
        "from prototypevector import PrototypeVector\n",
        "\n",
        "image_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).cuda()\n",
        "image_std = torch.tensor([0.26862954, 0.26130258, 0.27577711]).cuda()\n",
        "##### IMPORTANT!!!!! MAY NEED TO CHANGE THIS!!!!! #######"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma1oVYMNeAVC",
        "outputId": "f52053c3-d6f1-4545-bd1a-0072446d6cc5"
      },
      "source": [
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "--2021-04-26 19:10:34--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.40, 13.107.213.40, 2620:1ec:bdf::40, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-04-26 19:10:34 (74.6 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysUpoaCEeCLe"
      },
      "source": [
        "import os\n",
        "import skimage #Has some images in here - check original \"Interacting with CLIP.ipynb\" document\n",
        "import IPython.display\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1kch4FmlEY7"
      },
      "source": [
        "tokenizer = SimpleTokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_JOnXajlJn-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXcV8cXglOp0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAMuN5yclqlm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}