{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "metadata": {
      "interpreter": {
        "hash": "2a41893882cd6a4f9de9c4407ee80149143837d532b553c8457b9b80809c1765"
      }
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ae6877f3c4047718a440ea3194e52dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d59e80db72a94829bbb5fc8b231cf25c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0441ec4a136c4c70938678bffb0d6b75",
              "IPY_MODEL_2f7c279651f34a5cb0da0ea4848b44bc"
            ]
          }
        },
        "d59e80db72a94829bbb5fc8b231cf25c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0441ec4a136c4c70938678bffb0d6b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85c5b532edbd49a8805971f58773792d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c5f6d8c168f4a00841791a84bb1ad21"
          }
        },
        "2f7c279651f34a5cb0da0ea4848b44bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e29677ef5f6456682ee46c526b744f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [01:08&lt;00:00, 146.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3a6fc5cf319470b8463486b31e1f58a"
          }
        },
        "85c5b532edbd49a8805971f58773792d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c5f6d8c168f4a00841791a84bb1ad21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e29677ef5f6456682ee46c526b744f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3a6fc5cf319470b8463486b31e1f58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67ceae57c6094d17b4f329cc2cf2260d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0a69368b8b245a49f77fcb7c1f6298e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6fd59b17489945ab99d638e60755f962",
              "IPY_MODEL_5085ff19eeab419db33f22d5a23a415f"
            ]
          }
        },
        "a0a69368b8b245a49f77fcb7c1f6298e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fd59b17489945ab99d638e60755f962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d709283238404e6a9d1d973bdf054bf8",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d62d738711474a18a9a25a131bdf9fd0"
          }
        },
        "5085ff19eeab419db33f22d5a23a415f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d67c8b820f54ba5b194131758a071d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42732c37af004ef6ab4582f63ed3a2ad"
          }
        },
        "d709283238404e6a9d1d973bdf054bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d62d738711474a18a9a25a131bdf9fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d67c8b820f54ba5b194131758a071d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42732c37af004ef6ab4582f63ed3a2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerrychen109/cs197/blob/master/Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y10p9U6OhstD"
      },
      "source": [
        "MOUNT DRIVE + CONNECT GITHUB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs5lnQcwW8q7",
        "outputId": "49fdf457-0a30-4c5e-cede-024d314aaf32"
      },
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwf8s_YmVVRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e988b89-6f47-46e0-bba4-a20d79362db5"
      },
      "source": [
        "# FOLDERNAME = \"CS197\"\n",
        "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "import sys\n",
        "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# %cd /content/drive/My\\ Drive/$FOLDERNAME\n",
        "# ! git clone \"https://USERNAME:PASSWORD@github.com/jerrychen109/cs197.git\"\n",
        "# # NEED TO FIND OUT BETTER WAY (WITH TOKENS??) ^^\n",
        "# FOLDERNAME = \"3_SPR/cs197/fewshot-code\"\n",
        "FOLDERNAME = \"CS197/cs197/\"\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "# Commands for local changes error\n",
        "# ! git config --global user.email \"githubEMAIL\"\n",
        "# ! git config --global user.name \"githubUSERNAME\"\n",
        "# ! git stash push\n",
        "# ! git stash drop"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CS197/cs197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBiyaIBTUUXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d906181d-6bcb-4a84-87e0-2b8d86f22e55"
      },
      "source": [
        "! git pull \"https://USERNAME:PASSWORD@github.com/jerrychen109/cs197.git\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Invalid username or password.\n",
            "fatal: Authentication failed for 'https://USERNAME:PASSWORD@github.com/jerrychen109/cs197.git/'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTSSeXZEOFGu"
      },
      "source": [
        "# %cd datasets\n",
        "# !wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "# !tar -xzf cifar-10-python.tar.gz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMO2rSSNOUyL"
      },
      "source": [
        "# ! git config --global user.email \"\"\n",
        "# ! git config --global user.name \"\"\n",
        "# ! git commit . -m \"\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5aBrRkaPysw"
      },
      "source": [
        "# ! git push"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKRHS0kxiPRU"
      },
      "source": [
        "IMPORT LIBRARIES AND MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma1oVYMNeAVC",
        "cellView": "form",
        "outputId": "ec661cc1-af55-44a2-a68b-6ab6ba553fb6"
      },
      "source": [
        "#@title\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz\n",
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\"\n",
        "\n",
        "from collections import OrderedDict\n",
        "import IPython.display\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import skimage #Has some images in here - check original \"Interacting with CLIP.ipynb\" document\n",
        "import torch\n",
        "\n",
        "from prototype import Prototype\n",
        "from prototypevector import PrototypeVector\n",
        "from torchvision.datasets import CIFAR10, CIFAR100\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "from utils.data_utils import *\n",
        "from utils.image_utils import *\n",
        "from utils.text_utils import *\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/b5/5da463f9c7823e0e575e9908d004e2af4b36efa8d02d3d6dad57094fcb11/ftfy-6.0.1.tar.gz (63kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 20kB 32.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 30kB 37.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 40kB 30.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 51kB 28.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 61kB 31.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.1-cp37-none-any.whl size=41573 sha256=971ea10de7b3a8ea6458b7b145c0a0ec1cc19bd350f19de5959440492d3438f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/73/c7/9056e14b04919e5c262fe80b54133b1a88d73683d05d7ac65c\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.1\n",
            "--2021-05-11 06:15:45--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.40, 13.107.213.40, 2620:1ec:bdf::40, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-05-11 06:15:45 (60.5 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n",
            "CUDA version: 11.0\n",
            "Torch version: 1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrLC2hunVVRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67118ce1-f9c4-4dbd-d997-f0d81e333c4e"
      },
      "source": [
        "#@title\n",
        "CIFAR10_DIR = 'datasets/cifar-10-batches-py'\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(os.path.join(FOLDERNAME, CIFAR10_DIR)))\n",
        "TRAIN_BATCHES = [os.path.join(CIFAR10_DIR, batch_path) for batch_path in [\n",
        "    'data_batch_1',\n",
        "    'data_batch_2',\n",
        "    'data_batch_3',\n",
        "    'data_batch_4',\n",
        "    'data_batch_5'\n",
        "]]\n",
        "TEST_BATCH = os.path.join(CIFAR10_DIR, 'test_batch')\n",
        "\n",
        "train_data, train_labels = load_cifar10(TRAIN_BATCHES)\n",
        "test_data, test_labels = load_cifar10_batch(TEST_BATCH)\n",
        "\n",
        "print(\"train shape: \", train_data.shape)#[0])\n",
        "print(\"test shape: \", test_data.shape)#[0])\n",
        "\n",
        "train_data_dict = sample_classes(train_data, train_labels, per_class = 250)\n",
        "for c in train_data_dict:\n",
        "  train_data_dict[c] = resize_images(train_data_dict[c])\n",
        "MODELS = {\n",
        "    \"RN50\": \"https://openaipublic.azureedge.net/clip/models/afeb0e10f9e5a86da6080e35cf09123aca3b358a0c3e3b6c78a7b63bc04b6762/RN50.pt\",\n",
        "    \"RN101\": \"https://openaipublic.azureedge.net/clip/models/8fa8567bab74a42d41c5915025a8e4538c3bdbe8804a470a72f30b0d94fab599/RN101.pt\",\n",
        "    \"RN50x4\": \"https://openaipublic.azureedge.net/clip/models/7e526bd135e493cef0776de27d5f42653e6b4c8bf9e0f653bb11773263205fdd/RN50x4.pt\",\n",
        "    \"ViT-B/32\": \"https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\",    \n",
        "}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape:  torch.Size([50000, 3, 32, 32])\n",
            "test shape:  torch.Size([10000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K53T_iHZd7-W",
        "cellView": "form",
        "outputId": "3795f1a2-d510-4595-b129-000a98442559"
      },
      "source": [
        "#@title\n",
        "! wget {MODELS[\"ViT-B/32\"]} -O model.pt\n",
        "model = torch.jit.load(\"model.pt\").cuda().eval()\n",
        "input_resolution = model.input_resolution.item()\n",
        "context_length = model.context_length.item()\n",
        "vocab_size = model.vocab_size.item()\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Input resolution:\", input_resolution)\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-11 06:16:13--  https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.40, 13.107.213.40, 2620:1ec:bdf::40, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 353976522 (338M) [application/octet-stream]\n",
            "Saving to: ‘model.pt’\n",
            "\n",
            "model.pt            100%[===================>] 337.58M  66.4MB/s    in 5.1s    \n",
            "\n",
            "2021-05-11 06:16:18 (66.5 MB/s) - ‘model.pt’ saved [353976522/353976522]\n",
            "\n",
            "Model parameters: 151,277,313\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg8ArUFPig44"
      },
      "source": [
        "Calculate image mean and standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh3rtIhrd-el",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b22ef3-8e18-4234-c529-80409734dc43"
      },
      "source": [
        "image_mean = getImageMean(train_data).cuda()\n",
        "image_std = getImageStd(train_data).cuda()\n",
        "print (\"image mean: \", image_mean)\n",
        "print (\"image_std: \", image_std)\n",
        "# image_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).cuda()\n",
        "# image_std = torch.tensor([0.26862954, 0.26130258, 0.27577711]).cuda()\n",
        "##### IMPORTANT!!!!! NEED TO CHANGE THIS DEPENDING ON DATASET!!!!! #######"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image mean:  tensor([0.4914, 0.4822, 0.4465], device='cuda:0')\n",
            "image_std:  tensor([0.2470, 0.2435, 0.2616], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM1w9OVGiqgY"
      },
      "source": [
        "Initialize tokenizer\n",
        "\n",
        "Also: create descriptions, find filenames and graph images with labels and descriptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1kch4FmlEY7",
        "collapsed": true
      },
      "source": [
        "tokenizer = SimpleTokenizer()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Y6CYVProj7QQ"
      },
      "source": [
        "#@title\n",
        "# descriptions = {\n",
        "#     \"page\": \"a page of text about segmentation\",\n",
        "#     \"chelsea\": \"a facial photo of a tabby cat\",\n",
        "#     \"astronaut\": \"a portrait of an astronaut with the American flag\",\n",
        "#     \"rocket\": \"a rocket standing on a launchpad\",\n",
        "#     \"motorcycle_right\": \"a red motorcycle standing in a garage\",\n",
        "#     \"camera\": \"a person looking at a camera on a tripod\",\n",
        "#     \"horse\": \"a black-and-white silhouette of a horse\", \n",
        "#     \"coffee\": \"a cup of coffee on a saucer\"\n",
        "# }\n",
        "# filenames = getImageFilesFromDir(skimage.data_dir)\n",
        "# filenames\n",
        "# filenamesInDescriptions = sorted([x for x in filenames if x[:-4] in descriptions])\n",
        "# images = getImagesFromFiles(skimage.data_dir, filenamesInDescriptions)\n",
        "# labels = sorted(list(descriptions.keys()))\n",
        "# _ = graphImages(images, texts=labels, descriptions=descriptions)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3VTqKJGj_JO"
      },
      "source": [
        "Declare and initialize PrototypeVector\n",
        "- Add image mean and std so images can be standardized when passed into PrototypeVector\n",
        "- Add dict of training data (should we modify this to take in less?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPDB6l4EVVRQ"
      },
      "source": [
        "vector = PrototypeVector(model.encode_image, device, image_mean, image_std, k=1)\n",
        "vector.addPrototypesFromDict(train_data_dict)\n",
        "# vector.addPrototypesWithFilenames([skimage.data_dir]*len(labels), filenames_for_class, labels)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ICSkqltv8gn"
      },
      "source": [
        "- Take smaller sample of test data\n",
        "- Resized images (can we do multiple images at once??)\n",
        "- Create image encodings (good idea to do it here to save re-computation in prototypevector later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm_ndsBNn4Jd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "7ae6877f3c4047718a440ea3194e52dc",
            "d59e80db72a94829bbb5fc8b231cf25c",
            "0441ec4a136c4c70938678bffb0d6b75",
            "2f7c279651f34a5cb0da0ea4848b44bc",
            "85c5b532edbd49a8805971f58773792d",
            "0c5f6d8c168f4a00841791a84bb1ad21",
            "0e29677ef5f6456682ee46c526b744f6",
            "c3a6fc5cf319470b8463486b31e1f58a"
          ]
        },
        "outputId": "3d1a86b2-b8c9-4ffc-a357-3092aed938f6"
      },
      "source": [
        "# classification accuracy against test set\n",
        "print(test_data.shape)\n",
        "test_data_small = test_data[:1000]\n",
        "test_labels_small = test_labels[:1000]\n",
        "# Original (using old classify)\n",
        "# preds = []\n",
        "# nearests = []\n",
        "# encoded_images = []\n",
        "# for image, c in tqdm(zip(test_data, test_labels), total=len(test_data)):\n",
        "#   image = resize_images(image.unsqueeze(0))\n",
        "#   test_encoded = encodeImageWithFunc(model.encode_image, image).squeeze()\n",
        "#   encoded_images.append(test_encoded)\n",
        "#   label, nearest = vector.classify(cosineSimilarity, test_encoded)\n",
        "#   preds.append(label)\n",
        "#   nearests.append(nearest)\n",
        "\n",
        "# Standardizing attempt (uses a lot of memory, dimensions not lining up I'm not sure how to get correct dimensions using unsqueeze(0))\n",
        "# Ideally data_images is a list of images but there are some dimension issues\n",
        "\n",
        "# data_images = []\n",
        "# for image, c in tqdm(zip(test_data_small, test_labels_small), total=len(test_data_small)):\n",
        "#   image = resize_images(image.unsqueeze(0))\n",
        "#   data_images.append(image) \n",
        "# data_images = torch.tensor(np.stack(images)).cuda()\n",
        "# data_images -= image_mean[:, None, None]\n",
        "# data_images /= image_std[:, None, None]\n",
        "# data_images = encodeImageWithFunc(model.encode_image, data_images)\n",
        "# data_images = normalize(data_images)\n",
        "\n",
        "encoded_images = []\n",
        "for image, c in tqdm(zip(test_data, test_labels), total=len(test_data)):\n",
        "  image = resize_images(image.unsqueeze(0))\n",
        "  test_encoded = encodeImageWithFunc(model.encode_image, image).squeeze()\n",
        "  encoded_images.append(test_encoded)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ae6877f3c4047718a440ea3194e52dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCUsAnfqcQvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dbca80-38c5-41b8-cada-bde3d8401541"
      },
      "source": [
        "tuples = vector.classifyImages(cosineSimilarity, encoded_images, k=100, recalc=False)\n",
        "preds = [t[0] for t in tuples]\n",
        "test_acc = np.mean(np.array(preds) == np.array(test_labels))\n",
        "print(\"test accuracy: \", test_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.4624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfW4xRRiE4SY",
        "outputId": "faeaaa6b-1079-46ad-9308-5589a3955d19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tuples = vector.classifyImages(cosineSimilarity, encoded_images, k=10, recalc=False)\n",
        "preds = [t[0] for t in tuples]\n",
        "test_acc = np.mean(np.array(preds) == np.array(test_labels))\n",
        "print(\"test accuracy: \", test_acc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.4249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OxlrnPffqfN"
      },
      "source": [
        "def classifyImages(images, trueLabels, k, iter):\n",
        "\titerAccuracies = [0] * iter\n",
        "\tnumLabelCorrect = [0] * len(trueLabels)\n",
        "\ttotalCorrect = 0\n",
        "\tfor i in tqdm(range(iter)):\n",
        "\t\tfor j in range(len(images)):\n",
        "\t\t\ttup = vector.classify(cosineSimilarity, images[j])\n",
        "\t\t\tif tup[0] == trueLabels[j]:\n",
        "\t\t\t\titerAccuracies[i] += 1\n",
        "\t\t\t\t# numLabelCorrect[i] += 1   # Left this one here, not sure how to change\n",
        "\t\t\t\ttotalCorrect += 1\n",
        "\tfor i in range(len(iterAccuracies)):\n",
        "\t\titerAccuracies[i] /= len(images)\n",
        "\t# labelAccuracies = []\n",
        "\t# for i in range(len(numLabelCorrect)):\n",
        "\t\t# labelAccuracies.append((numLabelCorrect[i] / iter), label[i])\n",
        "\treturn (totalCorrect / (len(images) * iter)), iterAccuracies#, labelAccuracies"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug3n1K37i1iZ",
        "outputId": "b9ada3bb-9561-409b-c638-461cf242951e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315,
          "referenced_widgets": [
            "67ceae57c6094d17b4f329cc2cf2260d",
            "a0a69368b8b245a49f77fcb7c1f6298e",
            "6fd59b17489945ab99d638e60755f962",
            "5085ff19eeab419db33f22d5a23a415f",
            "d709283238404e6a9d1d973bdf054bf8",
            "d62d738711474a18a9a25a131bdf9fd0",
            "7d67c8b820f54ba5b194131758a071d3",
            "42732c37af004ef6ab4582f63ed3a2ad"
          ]
        }
      },
      "source": [
        "classifyImages(encoded_images[:100], test_labels[:100], 1, 1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67ceae57c6094d17b4f329cc2cf2260d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c7704cafe605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifyImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-2b10dc7b743a>\u001b[0m in \u001b[0;36mclassifyImages\u001b[0;34m(images, trueLabels, k, iter)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosineSimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrueLabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                 \u001b[0miterAccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PrototypeVector' object has no attribute 'classify'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HejaI8ypSwcz"
      },
      "source": [
        "multRuns = {}\n",
        "for k in range(11):\n",
        "  multRuns[k] = classifyImages(encoded_images[:500], test_labels[:500], k, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttiNcO4qqt78"
      },
      "source": [
        "prototype = Prototype()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6y4VXc7qdbg"
      },
      "source": [
        "multRuns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckCShZEBqfcV"
      },
      "source": [
        "data = np.array([(key, np.array(value[1])) for key, value in multRuns.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1w9v5BjojgJ"
      },
      "source": [
        "df = pd.DataFrame.from_records(np.array(data), columns=['k', 'Accuracy'])\n",
        "df = df.explode(\"Accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AudZBj1_srLo"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Ee4uBTlqvj"
      },
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "ax = sns.barplot(x=\"k\", y=\"Accuracy\", data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q7EhjTpphar"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy12IS58i4IS"
      },
      "source": [
        "# normalize(encoded_images[0]).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i07xpLlkKpG"
      },
      "source": [
        "# term = vector.getClassVectors(1)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hH2IRrqlab_"
      },
      "source": [
        "# term[1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W00trg0zldAZ"
      },
      "source": [
        "# vector.getLabelsToPrototypes()[0].getClassVector().shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}